{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Assignment-2.ipy",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srinath68/NLP/blob/main/NLP_Assignment_2_ipy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDltruKFQy80"
      },
      "source": [
        "A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.\n",
        "Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.\n",
        "1.\tConvert the above paragraph into vectors using:i)\tWord2vec\n",
        "ii)\tUSE\n",
        "iii)\tELMO\n",
        "iv)\tGP2\n",
        "v)\tSentence-BERT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDQ08bbU-ar1"
      },
      "source": [
        "paragraph='''A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.\n",
        "Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXxhVR_p_WVH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUlm8BU2DpBP",
        "outputId": "4b5f2d03-dc1d-47bc-f525-fb8497b3f79e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim import corpora,models,similarities"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGf9toIR_Wsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f7ca707-9aa0-4394-ff3c-76a8ca03082e"
      },
      "source": [
        "def essay_to_sentences(para):\n",
        "    tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw_sentences=tokenizer.tokenize(para.strip())\n",
        "    sentences=[]\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append((raw_sentence))\n",
        "    return sentences\n",
        "sentences= essay_to_sentences(paragraph)\n",
        "\n",
        "\n",
        "wordvecs=[nltk.word_tokenize(sent) for sent in sentences]\n",
        "stops=list(set(stopwords.words(\"english\")))\n",
        "\n",
        "for i in wordvecs:\n",
        "  for j in i:\n",
        "    if j in stops:\n",
        "      i.remove(j)\n",
        "    elif len(j)==1:\n",
        "      i.remove(j)\n",
        "\n",
        "model=gensim.models.Word2Vec(wordvecs,min_count=1,size=32)\n",
        "model['paragraph']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00778762,  0.01204301,  0.00991048, -0.00509115,  0.01378211,\n",
              "       -0.00451053, -0.0060953 , -0.00438694, -0.01559457,  0.01003721,\n",
              "        0.0132491 , -0.01326717, -0.01250992,  0.0011908 , -0.00168712,\n",
              "       -0.01364463,  0.01152416,  0.00328791, -0.01207458, -0.00011364,\n",
              "        0.00246571,  0.0140457 , -0.00107529,  0.01439384,  0.00587748,\n",
              "        0.00350567,  0.00235062,  0.0027146 , -0.0153346 ,  0.01351293,\n",
              "        0.01189841, -0.01555324], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKKnvnICTxdm",
        "outputId": "e2190833-821f-472d-d312-63c62b822a74"
      },
      "source": [
        "model.most_similar('sentence')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('series', 0.3638501763343811),\n",
              " ('is', 0.2946968674659729),\n",
              " ('the', 0.2542320489883423),\n",
              " ('examples', 0.24452349543571472),\n",
              " ('paragraphs', 0.24359798431396484),\n",
              " ('essay', 0.20885828137397766),\n",
              " ('kinds', 0.20520144701004028),\n",
              " ('or', 0.18503132462501526),\n",
              " ('every', 0.18367376923561096),\n",
              " ('are', 0.1665898710489273)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPJyBi6nT2XL",
        "outputId": "6a873c9a-6b7e-4d19-c925-24b18bb28aee"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "use= hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embeddings=use(sentences)\n",
        "print(embeddings)\n",
        "\n",
        "print(\"shape= \",embeddings[0].shape)\n",
        "print(\"The sentence: \",sentences[0],\"\\n is converted as : \\n{}\".format(embeddings[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder/4, Total size: 987.47MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.01168496 -0.0306057   0.06116336 ... -0.08641754  0.00025049\n",
            "   0.0548275 ]\n",
            " [ 0.02972507 -0.03655472  0.08002592 ... -0.07038905 -0.02832128\n",
            "   0.04804675]\n",
            " [ 0.07221662 -0.04182234  0.05336688 ... -0.06942354  0.01795933\n",
            "   0.06641506]\n",
            " ...\n",
            " [ 0.01586951 -0.05243038  0.06065089 ... -0.06435592  0.04215745\n",
            "   0.06304207]\n",
            " [ 0.04141247  0.0258891  -0.00625629 ... -0.0216299   0.00910816\n",
            "   0.03623573]\n",
            " [ 0.0157841  -0.02142678  0.00402447 ... -0.09605584 -0.06707881\n",
            "   0.0797038 ]], shape=(8, 512), dtype=float32)\n",
            "shape=  (512,)\n",
            "The sentence:  A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " is converted as : \n",
            "[ 1.16849560e-02 -3.06057017e-02  6.11633621e-02  8.47723708e-02\n",
            " -5.83404489e-03  2.84163468e-03  2.59479191e-02  3.90258408e-03\n",
            " -5.55585772e-02  5.68110794e-02 -8.95015243e-03 -4.50466387e-03\n",
            " -6.06310442e-02  3.18566710e-02 -6.86047748e-02 -9.39451531e-02\n",
            " -4.23613824e-02  3.93056907e-02 -9.02280435e-02 -5.53664006e-02\n",
            " -1.92775275e-03  5.99910133e-02  9.42121632e-03  6.07980192e-02\n",
            " -5.22601139e-03  1.28727444e-02 -2.15456896e-02 -4.93353941e-02\n",
            " -6.26435649e-05 -4.05308716e-02  7.90261030e-02 -5.32253878e-03\n",
            " -2.70436448e-03 -1.01282923e-02 -6.41689077e-02  2.35940833e-02\n",
            "  4.94742952e-02  1.76912267e-02 -7.69225741e-03  2.03442983e-02\n",
            "  1.55387660e-02  4.64376099e-02  3.61865498e-02  4.38465402e-02\n",
            "  6.95741177e-02  2.37604082e-02 -1.20333314e-03 -4.55583967e-02\n",
            " -3.44719328e-02  1.63743850e-02 -2.70779827e-03  5.60244247e-02\n",
            "  4.04605584e-04 -1.96648687e-02 -3.91405188e-02 -9.61556751e-03\n",
            "  2.14329711e-03  5.61526865e-02  2.82766894e-02  1.80720370e-02\n",
            "  1.23767182e-03 -3.25148366e-02  4.19939458e-02  6.37653619e-02\n",
            "  5.56223132e-02  1.44277113e-02  4.99183200e-02 -1.93575919e-02\n",
            "  5.64282723e-02 -6.90750107e-02  1.60090427e-03  2.10034288e-02\n",
            "  3.52526829e-02  6.35947958e-02 -7.65628442e-02  5.87279648e-02\n",
            " -4.10689116e-02  3.31177823e-02 -2.83570378e-03  7.48989219e-03\n",
            " -3.19783986e-02 -6.25580475e-02  4.89425249e-02  3.36479656e-02\n",
            "  2.12714821e-02  4.28444007e-03 -9.05722205e-04 -4.36473545e-03\n",
            " -9.23611596e-02 -3.89574021e-02  3.30829285e-02  9.61313583e-03\n",
            "  2.15857495e-02 -1.47692617e-02  1.38847157e-02  8.47374722e-02\n",
            " -8.47435743e-02 -4.44485061e-02  7.54610971e-02  1.65129453e-02\n",
            "  2.31740233e-02 -2.84716990e-02 -6.77682757e-02  4.24248986e-02\n",
            " -1.49503592e-02  8.38012435e-03  5.18886112e-02  3.92066501e-02\n",
            " -4.66535613e-02 -2.45939121e-02  7.14560214e-04 -3.46495281e-03\n",
            "  2.36652214e-02  3.31294052e-02 -5.71681373e-03  4.09859046e-02\n",
            " -8.35536197e-02 -1.66684259e-02 -3.52724735e-03  1.73547789e-02\n",
            "  2.53550634e-02 -2.66782902e-02 -2.51310002e-02 -4.68712337e-02\n",
            "  3.96435484e-02 -6.68355916e-03 -3.46517451e-02 -2.81814411e-02\n",
            "  4.19962741e-02 -3.24101634e-02  2.40438730e-02 -5.47123142e-03\n",
            "  2.89679635e-02  6.99753016e-02  3.75229120e-02 -8.82184207e-02\n",
            "  6.07020268e-03 -6.91123605e-02 -1.74328759e-02  2.53294259e-02\n",
            " -7.28369430e-02  2.37329230e-02  4.66296300e-02  4.23278324e-02\n",
            "  5.21277264e-02 -3.55562079e-03 -1.40107702e-02  2.05670781e-02\n",
            "  7.19133019e-02 -7.66954124e-02 -3.90844792e-02 -6.40899390e-02\n",
            "  2.43547019e-02  7.42070824e-02  2.84558237e-02 -7.93435350e-02\n",
            " -1.47222290e-02  6.70731207e-03  1.02058602e-02  1.25844395e-02\n",
            "  3.10074203e-02 -4.17215116e-02  6.03259392e-02  6.22179694e-02\n",
            "  2.10033357e-02 -1.65604427e-02  4.09302069e-03 -3.35808620e-02\n",
            "  7.28031397e-02  6.09729141e-02  4.15965449e-03  8.54913294e-02\n",
            "  1.31301405e-02 -6.34363294e-03 -5.07236198e-02  7.03543425e-02\n",
            "  3.73295657e-02  3.42008211e-02 -3.79130652e-05 -6.27389550e-02\n",
            "  4.80308495e-02 -2.81623136e-02 -7.19844922e-02  1.20989308e-02\n",
            " -4.26681750e-02  1.97790861e-02 -1.35227321e-02 -5.43040931e-02\n",
            " -4.83289249e-02 -2.65408549e-02  8.23441893e-02  5.54602779e-02\n",
            "  7.81148672e-02 -4.00111359e-03  2.02439576e-02  1.84899792e-02\n",
            " -1.52465152e-02  2.18962692e-02  3.17285247e-02  7.06312433e-02\n",
            "  3.70569807e-03  2.40870602e-02  1.94730132e-03 -7.16171972e-03\n",
            " -2.68035326e-02  3.17232609e-02  8.41562897e-02  2.63580456e-02\n",
            " -2.52104308e-02 -1.10670896e-02 -5.61277010e-02  3.97370905e-02\n",
            " -5.51151633e-02  6.12288751e-02  5.18368147e-02 -1.64934136e-02\n",
            "  1.84760767e-03  6.83429092e-02  6.94626272e-02  3.78927141e-02\n",
            " -5.02522588e-02 -2.57219318e-02  7.02316836e-02  3.36491652e-02\n",
            "  5.98834304e-04 -3.67769822e-02  4.44350429e-02  1.09023461e-02\n",
            "  4.34661582e-02 -6.98098838e-02 -2.62660198e-02  2.23397035e-02\n",
            "  9.15530045e-03 -6.15917519e-02  8.41568485e-02  3.92306112e-02\n",
            "  8.92866924e-02  1.28770825e-02  1.39245465e-02 -5.68395071e-02\n",
            " -7.46638998e-02  3.65591608e-02  1.06103271e-02 -6.25316948e-02\n",
            "  1.77653823e-02 -6.67558089e-02 -6.54299557e-02  4.47695814e-02\n",
            " -2.96407603e-02 -2.13827193e-02  3.60825285e-02 -8.18173289e-02\n",
            " -1.40964622e-02  1.33901201e-02  3.07124220e-02 -9.41405594e-02\n",
            "  3.03545687e-02 -2.68576331e-02  1.81657933e-02 -3.67770307e-02\n",
            "  3.33085544e-02  9.13278088e-02 -1.94911193e-02 -1.07954647e-02\n",
            " -9.28004365e-03 -4.06911317e-03  1.46724479e-02 -4.92432900e-02\n",
            "  1.71533916e-02 -5.45221418e-02 -6.61363974e-02 -7.90791959e-02\n",
            "  2.79752128e-02  3.62354293e-02  4.38261926e-02  1.96567699e-02\n",
            " -6.87820092e-02  2.44919062e-02  7.10261241e-02  9.12545249e-02\n",
            "  6.29523247e-02  1.67941470e-02  6.54825941e-02 -4.73535201e-03\n",
            " -4.48027998e-02 -1.61742344e-02  2.20355373e-02 -4.16113287e-02\n",
            "  1.13563165e-02 -3.63931693e-02 -2.76284032e-02  2.01356988e-02\n",
            " -8.22386369e-02 -2.58972440e-02 -4.15527746e-02 -5.79356402e-02\n",
            "  7.72940228e-03  4.06588912e-02 -1.13817723e-02  4.38650660e-02\n",
            " -1.07141612e-02 -4.62955385e-02  5.65050505e-02 -6.18267581e-02\n",
            " -3.84526476e-02 -4.90092188e-02  5.23114353e-02 -5.73057532e-02\n",
            " -1.15798600e-02  5.35165938e-03  2.78308745e-02 -4.59580868e-02\n",
            "  4.34778593e-02 -1.71735771e-02 -1.64880417e-02 -3.88848595e-02\n",
            " -6.44621579e-03  8.33479613e-02  3.65923420e-02  2.13971976e-02\n",
            " -2.59777438e-02 -6.10678010e-02  5.17178439e-02 -5.09534627e-02\n",
            " -8.41620862e-02 -2.87301559e-02 -8.05718228e-02  7.76726305e-02\n",
            "  4.12432253e-02 -3.67930345e-02  2.71156635e-02 -6.33789003e-02\n",
            "  2.25471351e-02 -3.28406021e-02 -9.11883265e-03  5.93739897e-02\n",
            " -7.64808897e-03  8.31478741e-03 -6.06922200e-03  6.88906759e-02\n",
            "  5.30840904e-02 -3.67047382e-03 -2.88561042e-02 -4.73021865e-02\n",
            " -9.18376297e-02 -8.83617345e-03  7.96945468e-02  5.93199208e-02\n",
            "  3.53019275e-02  7.12427124e-03 -7.07041621e-02  1.53525993e-02\n",
            "  4.09509800e-02  7.17416080e-03  7.37813264e-02  3.77231054e-02\n",
            " -9.00578871e-02 -3.24093625e-02  1.16494037e-02 -3.81786190e-02\n",
            "  2.34412216e-02 -2.10632626e-02 -7.03862235e-02  1.52055616e-03\n",
            " -1.61061995e-02  6.18526824e-02  7.94101954e-02  5.88109624e-03\n",
            " -1.51091143e-02 -3.21430266e-02  7.52916932e-03 -1.46266795e-03\n",
            "  6.74486384e-02  8.21412057e-02  1.35811390e-02  1.83010492e-02\n",
            "  3.14529352e-02  3.24921571e-02 -1.57691818e-02 -4.33157720e-02\n",
            " -4.35552225e-02 -1.21416850e-02  3.53558315e-03  4.30949926e-02\n",
            " -2.73923017e-02  2.91704629e-02 -8.02248940e-02 -2.86437925e-02\n",
            " -1.37747377e-02 -3.15168388e-02 -1.11740595e-02 -2.86996011e-02\n",
            " -3.92324366e-02  5.84819354e-02  5.46788890e-03 -2.98926253e-02\n",
            "  5.75807039e-03 -1.14696743e-02 -1.36441002e-02  2.66200788e-02\n",
            "  2.02788366e-03  3.45310047e-02 -5.55947274e-02  4.45481353e-02\n",
            "  7.75338756e-03  3.83887365e-02 -3.04163080e-02 -3.68546508e-02\n",
            " -5.83012365e-02  4.55889888e-02  4.12781835e-02 -2.69910283e-02\n",
            "  6.76821545e-02 -4.02726308e-02 -1.81559213e-02 -3.41260098e-02\n",
            "  5.10257073e-02  1.71381570e-02 -4.04662313e-03 -5.73980138e-02\n",
            "  1.24875652e-02 -6.49295151e-02 -7.56197646e-02  1.49736609e-02\n",
            "  2.50920225e-02  6.72385097e-02  5.28012663e-02  9.06193629e-02\n",
            " -5.04058860e-02  4.25336398e-02  2.04153005e-02 -6.48176670e-03\n",
            "  2.96379160e-02  4.65665059e-03 -4.00494225e-02 -5.69047444e-02\n",
            " -1.83908176e-02  2.06822567e-02  3.54513749e-02 -9.10554230e-02\n",
            " -2.56894622e-02  8.05328041e-02 -6.87960163e-02 -1.90876611e-02\n",
            " -4.92980296e-04 -1.21406903e-02 -8.38929228e-03  8.40041228e-03\n",
            "  7.14359134e-02 -1.60705596e-02  5.72944283e-02  3.03892442e-03\n",
            " -6.78497776e-02 -6.15831502e-02  7.88365379e-02 -6.56958222e-02\n",
            "  4.85723689e-02  6.67116046e-02  8.34890753e-02 -5.98137416e-02\n",
            " -1.69116743e-02  8.24893564e-02 -6.09520357e-03 -3.53484713e-02\n",
            " -2.27540694e-02 -9.13803428e-02 -4.53933552e-02 -8.25899374e-03\n",
            "  4.79642861e-02  7.68054500e-02 -3.04625407e-02 -1.50704850e-02\n",
            " -2.30549891e-02 -8.25552829e-03 -6.91696070e-03 -4.25775477e-04\n",
            "  3.37524004e-02 -2.74846070e-02 -9.42041818e-03 -6.28642738e-03\n",
            " -2.22889092e-02 -1.39351580e-02  6.23978395e-03 -8.72642621e-02\n",
            "  1.45548778e-02 -8.02355036e-02 -3.33042964e-02 -5.46392277e-02\n",
            "  4.86492962e-02  2.14733332e-02  3.27530093e-02 -1.53551195e-02\n",
            "  5.31828664e-02  1.56334732e-02  3.91777009e-02  6.98067434e-03\n",
            " -3.86222601e-02 -2.99131237e-02  1.69514846e-02  5.10435812e-02\n",
            "  3.60743403e-02 -5.03288545e-02  5.67543395e-02  7.83906505e-02\n",
            "  6.19171299e-02 -1.52612003e-02 -1.87837631e-02 -3.86124477e-02\n",
            "  6.28505424e-02 -8.64175409e-02  2.50492914e-04  5.48275039e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFgyKJKXEWMC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K41n8ciVBvA",
        "outputId": "0f4edd6c-1328-4aeb-b1a8-f0613e8b63ff"
      },
      "source": [
        "bert = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n",
        "embeddings2=bert(sentences)\n",
        "print(\"shape=\",embeddings2[0].shape)\n",
        "print(\"The sentence: \",sentences[0],\"\\n is converted as : \\n{}\".format(embeddings2[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape= (128,)\n",
            "The sentence:  A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " is converted as : \n",
            "[ 0.58439595  0.03570241  0.07089429  0.07733776 -0.01214658 -0.12435579\n",
            " -0.07824828 -0.00274544 -0.17964575  0.21627969  0.03844824 -0.19277166\n",
            " -0.12646586  0.02667335 -0.13363229 -0.00374018 -0.06618838  0.00353754\n",
            " -0.21084203  0.18731229  0.06417363  0.03025784  0.01986333 -0.08417947\n",
            "  0.03461034 -0.10283548 -0.0499575  -0.07064839 -0.04805086  0.01945524\n",
            " -0.00223823 -0.05097701 -0.06611909 -0.20404741  0.0077603  -0.030263\n",
            "  0.045775   -0.12902436 -0.01877959  0.01619794  0.11104539 -0.08053494\n",
            "  0.23449406 -0.0133885  -0.07351163  0.15601118  0.01348254 -0.12100593\n",
            " -0.0793598  -0.02779575  0.01043605 -0.05894459  0.05691529  0.06368439\n",
            "  0.0845022   0.00101441  0.09372724 -0.0798301   0.05913398 -0.1558554\n",
            " -0.10184948 -0.02461847 -0.02784929 -0.08858608  0.03941965 -0.16783947\n",
            " -0.14578974 -0.02660521  0.14279118 -0.07796778  0.16825287 -0.06649883\n",
            " -0.05502456 -0.05567321 -0.07227787 -0.02554577 -0.21921757 -0.12569019\n",
            " -0.12072967 -0.09969082 -0.01872542 -0.07315438  0.02047394  0.08561355\n",
            " -0.09803957 -0.0105774  -0.07032494  0.11166418  0.40513557  0.21004194\n",
            " -0.06189978  0.03889223 -0.08983729 -0.03319109 -0.0035341   0.08772231\n",
            "  0.10927039 -0.10206924 -0.14698724  0.09524962  0.0152119   0.08549073\n",
            "  0.09397376  0.18190913  0.11837611 -0.02253025  0.1460779  -0.06170215\n",
            " -0.05503973  0.0625353  -0.22137204 -0.00889415 -0.09505872 -0.11496251\n",
            "  0.19664201 -0.17894565 -0.0801039  -0.09435873 -0.01823526 -0.02143514\n",
            "  0.07827251 -0.06584725 -0.0418337  -0.18853487  0.03571585  0.16468506\n",
            "  0.01362591 -0.17049454]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCU9cNAmVY9K",
        "outputId": "c8de04ea-3b86-4154-f4e9-61c13026808c"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "\n",
        "elmo=hub.Module(\"https://tfhub.dev/google/elmo/3\",trainable=True)\n",
        "embeddings=elmo(\n",
        "    sentences,\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"elmo\"]\n",
        "init=tf.initialize_all_variables()\n",
        "sess=tf.Session()\n",
        "sess.run(init)\n",
        "print(\"\\n\\n\")\n",
        "print(sess.run(embeddings[0]))\n",
        "print(\"shape=\",embeddings[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/elmo/3'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/google/elmo/3, Total size: 357.40MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/elmo/3'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "[[ 0.29286996 -0.14378002 -0.32574052 ... -0.39559275 -0.35758832\n",
            "  -0.03588067]\n",
            " [-0.59441644  0.09640661  0.50537676 ...  0.22031897  0.26976916\n",
            "   0.46307242]\n",
            " [-0.17083307 -0.18744141 -0.27626717 ... -0.6755089   0.25390008\n",
            "   0.654027  ]\n",
            " ...\n",
            " [-0.02840841 -0.04353216  0.04130163 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]\n",
            " [-0.02840841 -0.04353216  0.04130163 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]\n",
            " [-0.02840841 -0.04353216  0.04130163 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]]\n",
            "shape= (32, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QWD6OjYY-ll"
      },
      "source": [
        "2). Find named entities (NER) for the above paragraph?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJiptXlHbGpF",
        "outputId": "fe30fd3a-8392-4534-cd2f-4d113a33b789"
      },
      "source": [
        "import torch\n",
        "!pip install -U sentence-transformers\n",
        "import transformers\n",
        "gptokenizer=transformers.GPT2Tokenizer.from_pretrained('gpt2-large')\n",
        "model=transformers.GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
        "output=gptokenizer.encode(paragraph ,add_special_tokens=False,return_tensors=\"pt\")\n",
        "print(\"shape=\",output.shape)\n",
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.12.5)\n",
            "Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.46)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.0.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "shape= torch.Size([1, 172])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   32,  7322,   318,   257,  2168,   286, 13439,   326,   389,  8389,\n",
              "           290, 24870,    11,   290,   389,   477,  3519,   284,   257,  2060,\n",
              "          7243,    13, 16699,   790,  3704,   286,  3597,   345,   466,   326,\n",
              "           318,  2392,   621,   257,  1178, 13439,   815,   307,  8389,   656,\n",
              "         23549,    13,   770,   318,   780, 23549,   905,   257,  9173,   810,\n",
              "           262, 45944,  3279,   286,   281, 14268,  2221,   290,   886,    11,\n",
              "           290,  4145,  1037,   262,  9173,   766,   262,  4009,   286,   262,\n",
              "         14268,   290, 13180,   663,  1388,  2173,    13,   198, 10044,  6111,\n",
              "            82,   460,  3994,   867,  1180,  6982,   286,  1321,    13,   317,\n",
              "          7322,   714,  3994,   257,  2168,   286,  4506,  6096,   393,   257,\n",
              "          2060,   890, 20936,   286,   257,  2276,   966,    13,   632,  1244,\n",
              "          6901,   257,  1295,    11,  2095,    11,   393,  1429,    26,  6664,\n",
              "           378,   257,  2168,   286,  2995,    26,  8996,   393,  6273,   734,\n",
              "           393,   517,  1243,    26, 36509,  3709,   656,  9376,    26,   393,\n",
              "          6901,  5640,   290,  3048,    13, 22250,   286,   262,  1611,   286,\n",
              "          1321,   484,  3994,    11,   477, 23549,  2648,  1728,  9695,    13,\n",
              "          1881,   286,   262,   749,  1593,   286,   777,   318,   257,  7243,\n",
              "          6827,    13]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-ukI3vlVqdk",
        "outputId": "eb2cf774-3829-42c3-daf2-b454ab31c36f"
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "gptokenizer=transformers.GPT2Tokenizer.from_pretrained('gpt2-large')\n",
        "model=transformers.GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
        "output=gptokenizer.encode(paragraph ,add_special_tokens=False,return_tensors=\"pt\")\n",
        "print(\"shape=\",output.shape)\n",
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape= torch.Size([1, 172])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   32,  7322,   318,   257,  2168,   286, 13439,   326,   389,  8389,\n",
              "           290, 24870,    11,   290,   389,   477,  3519,   284,   257,  2060,\n",
              "          7243,    13, 16699,   790,  3704,   286,  3597,   345,   466,   326,\n",
              "           318,  2392,   621,   257,  1178, 13439,   815,   307,  8389,   656,\n",
              "         23549,    13,   770,   318,   780, 23549,   905,   257,  9173,   810,\n",
              "           262, 45944,  3279,   286,   281, 14268,  2221,   290,   886,    11,\n",
              "           290,  4145,  1037,   262,  9173,   766,   262,  4009,   286,   262,\n",
              "         14268,   290, 13180,   663,  1388,  2173,    13,   198, 10044,  6111,\n",
              "            82,   460,  3994,   867,  1180,  6982,   286,  1321,    13,   317,\n",
              "          7322,   714,  3994,   257,  2168,   286,  4506,  6096,   393,   257,\n",
              "          2060,   890, 20936,   286,   257,  2276,   966,    13,   632,  1244,\n",
              "          6901,   257,  1295,    11,  2095,    11,   393,  1429,    26,  6664,\n",
              "           378,   257,  2168,   286,  2995,    26,  8996,   393,  6273,   734,\n",
              "           393,   517,  1243,    26, 36509,  3709,   656,  9376,    26,   393,\n",
              "          6901,  5640,   290,  3048,    13, 22250,   286,   262,  1611,   286,\n",
              "          1321,   484,  3994,    11,   477, 23549,  2648,  1728,  9695,    13,\n",
              "          1881,   286,   262,   749,  1593,   286,   777,   318,   257,  7243,\n",
              "          6827,    13]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCZ4gUhyW63v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "736d0f89-3e49-4cdb-8979-f21bb4e4cacc"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "ner=spacy.load('en')\n",
        "result=ner(paragraph)\n",
        "\n",
        "for word in result.ents:\n",
        "  print(word.text,word.label_)\n",
        "\n",
        "spacy.explain('GPE')\n",
        "displacy.render(result,style=\"ent\",jupyter=True)\n",
        "resultss=ner(\"The doctor is a person who looks after the sick people and prescribes medicines so that the patient recovers fast. In order to become a doctor, a person has to study medicine. Doctors lead a hard life. Their life is very busy. They get up early in the morning and go to the hospital. They work without taking a break. They always remain polite so that patients feel comfortable with them. Since doctors work so hard we must realise their value.\")\n",
        "for word in resultss.ents:\n",
        "  print(word.text,word.label_)\n",
        "\n",
        "displacy.render(resultss,style=\"ent\",jupyter=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "two CARDINAL\n",
            "One CARDINAL\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.</br>Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    One\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " of the most important of these is a topic sentence.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "early in the morning TIME\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The doctor is a person who looks after the sick people and prescribes medicines so that the patient recovers fast. In order to become a doctor, a person has to study medicine. Doctors lead a hard life. Their life is very busy. They get up \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    early in the morning\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
              "</mark>\n",
              " and go to the hospital. They work without taking a break. They always remain polite so that patients feel comfortable with them. Since doctors work so hard we must realise their value.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKL-3rVvY38d"
      },
      "source": [
        "3). Find similar sentences(repeated sentences) from the above paragraph?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn7m3CntYISf",
        "outputId": "cd3538d4-9bb4-43c6-83f0-60e320057bb1"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "se_embeddings = sbert_model.encode(sentences)\n",
        "q1_vec= sbert_model.encode(sentences[0])\n",
        "\n",
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "\n",
        "for sent in sentences:\n",
        "  sim = cosine(q1_vec, sbert_model.encode([sent])[0])\n",
        "\n",
        "  if sim>0.6:\n",
        "    print(\"Sentence1 =\",sentences[0],\"\\n \\nSentence2=\", sent, \"\\n\\nsimilarity = \", sim,end=\"\\n ----------------------------- \\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            "\n",
            "similarity =  1.0\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. \n",
            "\n",
            "similarity =  0.64775366\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= A paragraph could contain a series of brief examples or a single long illustration of a general point. \n",
            "\n",
            "similarity =  0.6927288\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= Regardless of the kind of information they contain, all paragraphs share certain characteristics. \n",
            "\n",
            "similarity =  0.787384\n",
            " ----------------------------- \n"
          ]
        }
      ]
    }
  ]
}